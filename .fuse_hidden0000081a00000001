import tensorflow as tf
import numpy
import read_data
from settings import THRESHOLD_0, THRESHOLD_128, THRESHOLD_192, THRESHOLD_254, height_start, height_end, width_start, \
    width_end, height, width, window_height, window_width


class DataSet(object):
    def __init__(self, images, labels, batch_size, dtype=tf.float32):
        sample_numbers = len(images)
        dtype = tf.as_dtype(dtype).base_dtype

        if dtype == tf.float32:
            # Convert from [0, 255] -> [0.0, 1.0].
            images = numpy.multiply(images, 1.0 / 1.0)
            labels = numpy.multiply(labels, 1)
            self.sample_numbers = sample_numbers
            self.batch_size = batch_size
            self._images = images
            self._labels = labels
            self._epochs_completed = 0
            self._index_in_epoch = 0

    def count(self):
        return self.sample_numbers

    def next_batch(self):
        start = self._index_in_epoch
        self._index_in_epoch += self.batch_size
        if self._index_in_epoch > self.sample_numbers:
            # epoch is finished
            self._epochs_completed += 1
            # Shuffle data
            perm = numpy.arange(self.sample_numbers)
            numpy.random.shuffle(perm)
            self._images = self._images[perm]
            self._labels = self._labels[perm]
            # Start next epoch
            start = 0
            self._index_in_epoch = self.batch_size
            assert self.batch_size <= self.sample_numbers
        end = self._index_in_epoch
        return self._images[start:end], self._labels[start:end]


thresholds = {
    0: THRESHOLD_0,
    128: THRESHOLD_128,
    192: THRESHOLD_192,
    254: THRESHOLD_254,
}


def convert_label_to_thresholds(element):
    return thresholds[element]

def get_rectangle(image, start_point):
    return image[start_point[0]:start_point[0] + window_height, start_point[1]:start_point[1] + window_width]

convert_label_to_thresholds = numpy.vectorize(convert_label_to_thresholds)

imgs = []
labels = []
parts_of_img = []
parts_of_lbl = []
from scipy.ndimage.filters import gaussian_filter

for i in xrange(1126):
    print i
    img, lbl = read_data.get_file(i + 1, column_format=True)
    img = img.reshape(256, 256)
    img = img[height_start:height_end, width_start:width_end]
    lbl = lbl.reshape(256, 256)
    lbl = lbl[height_start:height_end, width_start:width_end]
    for j in xrange(10):
        for k in xrange(10):
            start_point = [window_height * j, window_width * k]
            part_of_img = get_rectangle(img, start_point)
            part_of_lbl = get_rectangle(lbl, start_point)
            part_of_img = part_of_img.reshape(window_height * window_width, )
            part_of_lbl = part_of_lbl.reshape(window_height * window_width, )
            max_part_of_img = numpy.max(part_of_img)
            min_part_of_img = numpy.min(part_of_img)
            if i == 896:
                max_img = 12
            part_of_img = numpy.multiply(part_of_img - min_part_of_img, 1.0 / float(max_part_of_img - min_part_of_img))
            part_of_lbl = part_of_lbl.astype('float')
            part_of_lbl = convert_label_to_thresholds(part_of_lbl)
            parts_of_img.append(part_of_img)
            parts_of_lbl.append(part_of_lbl)
    img = img.reshape(height * width, )
    lbl = lbl.reshape(height * width, )
    # img = gaussian_filter(img, sigma=7)
    max_img = numpy.max(img)
    min_img = numpy.min(img)
    if i == 896:
        max_img = 12
    img = numpy.multiply(img - min_img, 1.0 / float(max_img - min_img))
    lbl = lbl.astype('float')
    lbl = convert_label_to_thresholds(lbl)
    imgs.append(img)
    labels.append(lbl)


# train_set = DataSet(imgs[:1000], labels[:1000], 40, dtype=tf.float32)
# test_set = DataSet(imgs[1000 + 1:], labels[1000 + 1:], 25, dtype=tf.float32)
train_set = DataSet(parts_of_img[:110000], parts_of_lbl[:110000], 40, dtype=tf.float32)
test_set = DataSet(parts_of_img[110000 + 1:], parts_of_lbl[110000 + 1:], 25, dtype=tf.float32)